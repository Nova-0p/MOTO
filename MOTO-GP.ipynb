{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820cc1c2-127c-4221-98cb-a57d4cd80d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "def log_system_resources():\n",
    "    \"\"\"Log current system resource usage\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"\\nMemory Usage: {mem.used/1e9:.2f}GB / {mem.total/1e9:.2f}GB ({mem.percent}%)\")\n",
    "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
    "    print(f\"Time: {time.strftime('%H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e673c60-8241-47b0-be58-42d2aa78d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "categorical_features = []\n",
    "numerical_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f90f4b1-2ce8-42c8-a461-d9ca45e4d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load all datasets\"\"\"\n",
    "    print(\"Loading datasets...\")\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    val_df = pd.read_csv('val.csv')\n",
    "    \n",
    "    print(f\"Train shape: {train_df.shape}\")\n",
    "    print(f\"Test shape: {test_df.shape}\")\n",
    "    print(f\"Validation shape: {val_df.shape}\")\n",
    "    \n",
    "    return train_df, test_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1302de-c75d-41c7-97f0-8ac38d527ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_analysis(train_df):\n",
    "    \"\"\"Quick EDA to understand the data better\"\"\"\n",
    "    print(\"\\n=== EXPLORATORY DATA ANALYSIS ===\")\n",
    "    print(f\"Target variable stats:\")\n",
    "    print(train_df['Lap_Time_Seconds'].describe())\n",
    "    \n",
    "    print(f\"\\nMissing values in train:\")\n",
    "    print(train_df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "    \n",
    "    print(f\"\\nCorrelation with target (top 10):\")\n",
    "    corr_target = train_df.corr()['Lap_Time_Seconds'].abs().sort_values(ascending=False)\n",
    "    print(corr_target.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bff7c89-b563-47a2-b1e6-1874d79b95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, is_train=True):\n",
    "    \"\"\"Competition-grade feature engineering\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Core performance features\n",
    "    if all(col in df.columns for col in ['Circuit_Length_km', 'Laps']):\n",
    "        df['Total_Distance'] = df['Circuit_Length_km'] * df['Laps']\n",
    "        df['Inverse_Circuit_Length'] = 1 / (df['Circuit_Length_km'] + 1e-6)\n",
    "    \n",
    "    # Speed dynamics\n",
    "    if 'Avg_Speed_kmh' in df.columns:\n",
    "        df['Speed_Squared'] = df['Avg_Speed_kmh'] ** 2\n",
    "        if 'Circuit_Length_km' in df.columns:\n",
    "            df['Speed_to_Length_Ratio'] = df['Avg_Speed_kmh'] / (df['Circuit_Length_km'] + 1e-6)\n",
    "    \n",
    "    # Position and championship features\n",
    "    if 'Grid_Position' in df.columns:\n",
    "        df['Grid_Advantage'] = 1 / (df['Grid_Position'] + 1)\n",
    "        df['Top_3_Grid'] = (df['Grid_Position'] <= 3).astype(int)\n",
    "    \n",
    "    if all(col in df.columns for col in ['Championship_Points', 'Championship_Position']):\n",
    "        df['Points_per_Position'] = df['Championship_Points'] / (df['Championship_Position'] + 1)\n",
    "        df['Is_Champion'] = (df['Championship_Position'] == 1).astype(int)\n",
    "    \n",
    "    # Weather interactions\n",
    "    if 'Weather_Condition' in df.columns:\n",
    "        weather_map = {'Dry': 0, 'Wet': 1, 'Mixed': 0.5, 'Unknown': 0.25}\n",
    "        df['Weather_Numeric'] = df['Weather_Condition'].map(weather_map).fillna(0)\n",
    "        \n",
    "        if 'Avg_Speed_kmh' in df.columns:\n",
    "            df['Speed_Weather_Interaction'] = df['Avg_Speed_kmh'] * (1 - df['Weather_Numeric'])\n",
    "    \n",
    "    # Tire strategy\n",
    "    if all(col in df.columns for col in ['Tire_Compound_Front', 'Tire_Compound_Rear']):\n",
    "        df['Same_Tire_Compound'] = (df['Tire_Compound_Front'] == df['Tire_Compound_Rear']).astype(int)\n",
    "    \n",
    "    # Track characteristics\n",
    "    if all(col in df.columns for col in ['Corners_per_Lap', 'Circuit_Length_km']):\n",
    "        df['Corner_Density'] = df['Corners_per_Lap'] / (df['Circuit_Length_km'] + 1e-6)\n",
    "    \n",
    "    # Rider experience (only for training data)\n",
    "    if is_train and all(col in df.columns for col in ['Years_active', 'Starts']):\n",
    "        df['Experience_Factor'] = np.log1p(df['Years_active']) * np.log1p(df['Starts'])\n",
    "        df['Finish_Rate'] = df['Finishes'] / (df['Starts'] + 1e-6)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5e309d-cbd0-4648-b132-46aa65d7f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(train_df, test_df, val_df):\n",
    "    \"\"\"Prepare features for modeling - FIXED VERSION\"\"\"\n",
    "    global label_encoders, categorical_features, numerical_features\n",
    "    \n",
    "    print(\"\\n=== FEATURE PREPARATION ===\")\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    train_processed = feature_engineering(train_df, is_train=True)\n",
    "    test_processed = feature_engineering(test_df, is_train=False)\n",
    "    val_processed = feature_engineering(val_df, is_train=True)\n",
    "    \n",
    "    # Identify categorical and numerical features\n",
    "    categorical_cols = [col for col in train_processed.columns \n",
    "                       if train_processed[col].dtype == 'object' and col != 'Lap_Time_Seconds']\n",
    "    numerical_cols = [col for col in train_processed.columns \n",
    "                     if col != 'Lap_Time_Seconds' and col not in categorical_cols]\n",
    "    \n",
    "    categorical_features = categorical_cols\n",
    "    numerical_features = numerical_cols\n",
    "    \n",
    "    print(f\"Categorical features: {len(categorical_cols)}\")\n",
    "    print(f\"Numerical features: {len(numerical_cols)}\")\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        # Combine all data to ensure consistent encoding\n",
    "        combined = pd.concat([train_processed[col], test_processed[col], val_processed[col]])\n",
    "        le.fit(combined.astype(str))\n",
    "        train_processed[col] = le.transform(train_processed[col].astype(str))\n",
    "        test_processed[col] = le.transform(test_processed[col].astype(str))\n",
    "        val_processed[col] = le.transform(val_processed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "    return train_processed, test_processed, val_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96d543a-1951-4c67-a985-0c3d815fd0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, cv_folds=5):\n",
    "    \"\"\"Optuna objective function for hyperparameter tuning\"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 800, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 1),\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 50,\n",
    "        'random_seed': 42,\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_val_fold, y_val_fold),\n",
    "            cat_features=categorical_features,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
    "        cv_scores.append(rmse)\n",
    "        \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42737469-194f-46cf-9af6-dc363bde2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, cv_folds=5):\n",
    "    \"\"\"Cross validation to estimate model performance\"\"\"\n",
    "    print(f\"\\n=== {cv_folds}-FOLD CROSS VALIDATION ===\")\n",
    "    \n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    mae_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"Training fold {fold + 1}/{cv_folds}...\")\n",
    "        \n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = CatBoostRegressor(\n",
    "            iterations=1000,\n",
    "            learning_rate=0.1,\n",
    "            depth=6,\n",
    "            l2_leaf_reg=3,\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_val_fold, y_val_fold),\n",
    "            cat_features=categorical_features,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
    "        mae = mean_absolute_error(y_val_fold, y_pred)\n",
    "        \n",
    "        cv_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        print(f\"Fold {fold + 1} RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "    \n",
    "    print(f\"\\nCV Results:\")\n",
    "    print(f\"Mean RMSE: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")\n",
    "    print(f\"Mean MAE: {np.mean(mae_scores):.4f} Â± {np.std(mae_scores):.4f}\")\n",
    "    \n",
    "    return cv_scores, mae_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48429c7-06f2-451b-b4b7-4647adffffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, optimize_hyperparams=True):\n",
    "    \"\"\"Competition-optimized model training for single CatBoost model\"\"\"\n",
    "    print(\"\\n=== MODEL TRAINING ===\")\n",
    "    \n",
    "    if optimize_hyperparams:\n",
    "        print(\"Starting hyperparameter optimization...\")\n",
    "        \n",
    "        # Use smaller subset for faster tuning\n",
    "        X_tune, _, y_tune, _ = train_test_split(\n",
    "            X_train, y_train, \n",
    "            train_size=0.2,  # Use 20% of data for tuning\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        def objective(trial):\n",
    "            # Progress reporting\n",
    "            trial_number = trial.number\n",
    "            if trial_number % 5 == 0:\n",
    "                print(f\"Running trial {trial_number}...\")\n",
    "            \n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 800, 1200),  # Reduced range\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "                'depth': trial.suggest_int('depth', 6, 8),  # Smaller range\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 5),\n",
    "                'random_strength': trial.suggest_float('random_strength', 0.1, 0.3),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.5, 0.8),\n",
    "                'border_count': trial.suggest_int('border_count', 64, 128),  # Reduced\n",
    "                'grow_policy': 'Depthwise',  # Fixed for simplicity\n",
    "                'loss_function': 'RMSE',\n",
    "                'eval_metric': 'RMSE',\n",
    "                'random_seed': 42,\n",
    "                'task_type': 'GPU' if torch.cuda.is_available() else 'CPU',\n",
    "                'verbose': False\n",
    "            }\n",
    "            \n",
    "            # Faster 2-fold CV\n",
    "            kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "            cv_scores = []\n",
    "            \n",
    "            for train_idx, val_idx in kf.split(X_tune):\n",
    "                X_train_fold, X_val_fold = X_tune.iloc[train_idx], X_tune.iloc[val_idx]\n",
    "                y_train_fold, y_val_fold = y_tune.iloc[train_idx], y_tune.iloc[val_idx]\n",
    "                \n",
    "                model = CatBoostRegressor(**params)\n",
    "                model.fit(\n",
    "                    X_train_fold, y_train_fold,\n",
    "                    cat_features=categorical_features,\n",
    "                    verbose=False,\n",
    "                    early_stopping_rounds=20  # Added early stopping\n",
    "                )\n",
    "                \n",
    "                y_pred = model.predict(X_val_fold)\n",
    "                rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
    "                cv_scores.append(rmse)\n",
    "            \n",
    "            return np.mean(cv_scores)\n",
    "        \n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(objective, n_trials=15, timeout=1800)  # 15 trials max, 30 min timeout\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best CV RMSE: {study.best_value:.4f}\")\n",
    "    else:\n",
    "        # Default parameters\n",
    "        best_params = {\n",
    "            'iterations': 1000,\n",
    "            'learning_rate': 0.05,\n",
    "            'depth': 7,\n",
    "            'l2_leaf_reg': 3,\n",
    "            'random_strength': 0.2,\n",
    "            'bagging_temperature': 0.7,\n",
    "            'border_count': 128,\n",
    "            'grow_policy': 'Depthwise',\n",
    "            'loss_function': 'RMSE',\n",
    "            'random_seed': 42,\n",
    "            'task_type': 'GPU' if torch.cuda.is_available() else 'CPU'\n",
    "        }\n",
    "    \n",
    "    # Train final model on full data with early stopping\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    final_params = {\n",
    "        **best_params,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbose': 100\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(**final_params)\n",
    "    model.fit(\n",
    "        X_train_split, y_train_split,\n",
    "        eval_set=(X_val_split, y_val_split),\n",
    "        cat_features=categorical_features,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = model.get_feature_importance(prettified=True)\n",
    "    print(\"\\nTop 20 most important features:\")\n",
    "    print(feature_importance.head(20))\n",
    "    \n",
    "    return model, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583690b4-2295-4cf5-a8b3-0e1b82836b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, X_val, y_val):\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    val_mae = mean_absolute_error(y_val, val_pred)\n",
    "\n",
    "    print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "    return val_pred, val_rmse, val_mae\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "798ebc27-c49d-4f17-bdbf-40f193992af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, X_val, y_val):\n",
    "    \"\"\"Validate model on validation set\"\"\"\n",
    "    print(\"\\n=== VALIDATION SET PERFORMANCE ===\")\n",
    "    \n",
    "    val_pred = model.predict(X_val)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    val_mae = mean_absolute_error(y_val, val_pred)\n",
    "    \n",
    "    print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "    \n",
    "    return val_pred, val_rmse, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a9103f-9d7f-4299-b0eb-3dc0888b1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(model, X_test):\n",
    "    \"\"\"Make predictions on test set\"\"\"\n",
    "    print(\"\\n=== GENERATING TEST PREDICTIONS ===\")\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred\n",
    "\n",
    "def create_submission(test_pred, sample_submission_path='sample_submission.csv'):\n",
    "    \"\"\"Create submission file\"\"\"\n",
    "    try:\n",
    "        sample_sub = pd.read_csv(sample_submission_path)\n",
    "        sample_sub.iloc[:, 1] = test_pred  # Assuming second column is the target\n",
    "        sample_sub.to_csv('submission.csv', index=False)\n",
    "        print(\"Submission file created: submission.csv\")\n",
    "    except:\n",
    "        # If sample submission not available, create basic submission\n",
    "        submission = pd.DataFrame({\n",
    "            'id': range(len(test_pred)),\n",
    "            'Lap_Time_Seconds': test_pred\n",
    "        })\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "        print(\"Basic submission file created: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c876de0-eb10-49d1-b805-82b9f1d21c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_competition_pipeline():\n",
    "    \"\"\"Complete competition-optimized pipeline with single CatBoost model\"\"\"\n",
    "    print(\"ðŸ STARTING COMPETITION PIPELINE ðŸ\")\n",
    "    \n",
    "    # 1. Load and prepare data\n",
    "    print(\"\\n=== LOADING DATA ===\")\n",
    "    train_df, test_df, val_df = load_data()\n",
    "    \n",
    "    # 2. Feature engineering\n",
    "    print(\"\\n=== FEATURE ENGINEERING ===\")\n",
    "    train_processed = feature_engineering(train_df, is_train=True)\n",
    "    test_processed = feature_engineering(test_df, is_train=False)\n",
    "    val_processed = feature_engineering(val_df, is_train=True)\n",
    "    \n",
    "    # 3. Feature encoding and selection\n",
    "    print(\"\\n=== FEATURE PREPARATION ===\")\n",
    "    train_final, test_final, val_final = prepare_features(\n",
    "        train_processed, test_processed, val_processed\n",
    "    )\n",
    "    \n",
    "    # Prepare datasets\n",
    "    feature_cols = categorical_features + numerical_features\n",
    "    X_train = train_final[feature_cols]\n",
    "    y_train = train_final['Lap_Time_Seconds']\n",
    "    X_val = val_final[feature_cols]\n",
    "    y_val = val_final['Lap_Time_Seconds']\n",
    "    X_test = test_final[feature_cols]\n",
    "    \n",
    "    # 4. Train single CatBoost model\n",
    "    print(\"\\n=== TRAINING SINGLE MODEL ===\")\n",
    "    model, feature_importance = train_model(X_train, y_train, optimize_hyperparams=True)\n",
    "    \n",
    "    # 5. Validate model\n",
    "    print(\"\\n=== MODEL VALIDATION ===\")\n",
    "    val_pred, val_rmse, val_mae = validate_model(model, X_val, y_val)\n",
    "    \n",
    "    # 6. Make test predictions\n",
    "    print(\"\\n=== TEST PREDICTIONS ===\")\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 7. Create submission\n",
    "    print(\"\\n=== CREATING SUBMISSION ===\")\n",
    "    submission = pd.DataFrame({\n",
    "        'Unique ID': test_df['Unique ID'],\n",
    "        'Lap_Time_Seconds': test_pred\n",
    "    })\n",
    "    submission.to_csv('competition_submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nðŸ† COMPETITION PIPELINE COMPLETE! ðŸ†\")\n",
    "    print(f\"Final validation RMSE: {val_rmse:.4f}\")\n",
    "    print(\"Submission saved as 'competition_submission.csv'\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_mae': val_mae,\n",
    "        'test_predictions': test_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e9f8b89-17d9-4f74-b8b0-9df02fea13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_test():\n",
    "    \"\"\"Quick test with minimal hyperparameter tuning\"\"\"\n",
    "    print(\"ðŸï¸ QUICK TEST MODE - MOTOGP LAP TIME PREDICTION ðŸï¸\")\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        train_df, test_df, val_df = load_data()\n",
    "        \n",
    "        # EDA\n",
    "        exploratory_analysis(train_df)\n",
    "        \n",
    "        # Prepare features\n",
    "        train_processed, test_processed, val_processed = prepare_features(\n",
    "            train_df, test_df, val_df\n",
    "        )\n",
    "        \n",
    "        # Prepare training data\n",
    "        feature_cols = categorical_features + numerical_features\n",
    "        X_train = train_processed[feature_cols]\n",
    "        y_train = train_processed['Lap_Time_Seconds']\n",
    "        \n",
    "        X_test = test_processed[feature_cols]\n",
    "        X_val = val_processed[feature_cols]\n",
    "        y_val = val_processed['Lap_Time_Seconds']\n",
    "        \n",
    "        print(f\"\\nFinal feature set: {len(feature_cols)} features\")\n",
    "        \n",
    "        # Quick cross validation (3 folds)\n",
    "        cv_scores, mae_scores = cross_validate(X_train, y_train, cv_folds=3)\n",
    "        \n",
    "        # Train model (no hyperparameter optimization)\n",
    "        model, feature_importance = train_model(X_train, y_train, optimize_hyperparams=False)\n",
    "        \n",
    "        # Validate\n",
    "        val_pred, val_rmse, val_mae = validate_model(model, X_val, y_val)\n",
    "        \n",
    "        # Predict test set\n",
    "        test_pred = predict_test(model, X_test)\n",
    "        \n",
    "        # Create submission\n",
    "        create_submission(test_pred)\n",
    "        \n",
    "        print(\"\\nðŸ† QUICK TEST COMPLETED SUCCESSFULLY! ðŸ†\")\n",
    "        print(f\"Final validation RMSE: {val_rmse:.4f}\")\n",
    "        print(\"Check 'submission.csv' for your predictions!\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'cv_rmse_mean': np.mean(cv_scores),\n",
    "            'cv_rmse_std': np.std(cv_scores),\n",
    "            'val_rmse': val_rmse,\n",
    "            'val_mae': val_mae,\n",
    "            'feature_importance': feature_importance,\n",
    "            'test_predictions': test_pred\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {str(e)}\")\n",
    "        print(\"Please check your data files and try again.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33c68ab-fb23-40df-b2c3-73e6f0e60714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_test():\n",
    "    \"\"\"Full test with hyperparameter optimization\"\"\"\n",
    "    print(\"ðŸï¸ FULL TEST MODE - MOTOGP LAP TIME PREDICTION ðŸï¸\")\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        train_df, test_df, val_df = load_data()\n",
    "        \n",
    "        # EDA\n",
    "        exploratory_analysis(train_df)\n",
    "        \n",
    "        # Prepare features\n",
    "        train_processed, test_processed, val_processed = prepare_features(\n",
    "            train_df, test_df, val_df\n",
    "        )\n",
    "        \n",
    "        # Prepare training data\n",
    "        feature_cols = categorical_features + numerical_features\n",
    "        X_train = train_processed[feature_cols]\n",
    "        y_train = train_processed['Lap_Time_Seconds']\n",
    "        \n",
    "        X_test = test_processed[feature_cols]\n",
    "        X_val = val_processed[feature_cols]\n",
    "        y_val = val_processed['Lap_Time_Seconds']\n",
    "        \n",
    "        print(f\"\\nFinal feature set: {len(feature_cols)} features\")\n",
    "        \n",
    "        # Full cross validation\n",
    "        cv_scores, mae_scores = cross_validate(X_train, y_train, cv_folds=5)\n",
    "        \n",
    "        # Train model with hyperparameter optimization\n",
    "        model, feature_importance = train_model(X_train, y_train, optimize_hyperparams=True)\n",
    "        \n",
    "        # Validate\n",
    "        val_pred, val_rmse, val_mae = validate_model(model, X_val, y_val)\n",
    "        \n",
    "        # Predict test set\n",
    "        test_pred = predict_test(model, X_test)\n",
    "        \n",
    "        # Create submission\n",
    "        create_submission(test_pred)\n",
    "        \n",
    "        print(\"\\nðŸ† FULL TEST COMPLETED SUCCESSFULLY! ðŸ†\")\n",
    "        print(f\"Final validation RMSE: {val_rmse:.4f}\")\n",
    "        print(\"Check 'submission.csv' for your predictions!\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'cv_rmse_mean': np.mean(cv_scores),\n",
    "            'cv_rmse_std': np.std(cv_scores),\n",
    "            'val_rmse': val_rmse,\n",
    "            'val_mae': val_mae,\n",
    "            'feature_importance': feature_importance,\n",
    "            'test_predictions': test_pred\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {str(e)}\")\n",
    "        print(\"Please check your data files and try again.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2541e2eb-caa7-43e1-9b95-6ab6dfe724e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train shape: (1914056, 45)\n",
      "Test shape: (546874, 44)\n",
      "Validation shape: (273437, 45)\n",
      "\n",
      "=== FEATURE PREPARATION ===\n",
      "Categorical features: 13\n",
      "Numerical features: 41\n",
      "\n",
      "=== MODEL TRAINING ===\n",
      "0:\tlearn: 11.5035512\ttest: 11.5162518\tbest: 11.5162518 (0)\ttotal: 1.07s\tremaining: 17m 48s\n",
      "100:\tlearn: 11.0224320\ttest: 11.0023837\tbest: 11.0023837 (100)\ttotal: 56.6s\tremaining: 8m 24s\n",
      "200:\tlearn: 10.6516039\ttest: 10.6356449\tbest: 10.6356449 (200)\ttotal: 1m 47s\tremaining: 7m 9s\n",
      "300:\tlearn: 10.2718925\ttest: 10.2626600\tbest: 10.2626600 (300)\ttotal: 2m 47s\tremaining: 6m 28s\n",
      "400:\tlearn: 9.9194596\ttest: 9.9177826\tbest: 9.9177826 (400)\ttotal: 3m 44s\tremaining: 5m 35s\n",
      "500:\tlearn: 9.5906057\ttest: 9.5945687\tbest: 9.5945687 (500)\ttotal: 4m 40s\tremaining: 4m 39s\n",
      "600:\tlearn: 9.2861783\ttest: 9.2933390\tbest: 9.2933390 (600)\ttotal: 5m 37s\tremaining: 3m 43s\n",
      "700:\tlearn: 8.9951090\ttest: 9.0051753\tbest: 9.0051753 (700)\ttotal: 6m 33s\tremaining: 2m 47s\n",
      "800:\tlearn: 8.7123601\ttest: 8.7246278\tbest: 8.7246278 (800)\ttotal: 7m 28s\tremaining: 1m 51s\n",
      "900:\tlearn: 8.4564683\ttest: 8.4716681\tbest: 8.4716681 (900)\ttotal: 8m 24s\tremaining: 55.4s\n",
      "999:\tlearn: 8.2713959\ttest: 8.2889590\tbest: 8.2889590 (999)\ttotal: 9m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 8.288958958\n",
      "bestIteration = 999\n",
      "\n",
      "\n",
      "Top 20 most important features:\n",
      "                         Feature Id  Importances\n",
      "0         Pit_Stop_Duration_Seconds     8.731386\n",
      "1       Ambient_Temperature_Celsius     8.248546\n",
      "2         Track_Temperature_Celsius     8.125194\n",
      "3                        rider_name     7.394994\n",
      "4   Tire_Degradation_Factor_per_Lap     7.209192\n",
      "5                   Corners_per_Lap     4.695742\n",
      "6                          position     4.375884\n",
      "7                          sequence     3.492196\n",
      "8                            year_x     3.458746\n",
      "9                            points     3.209109\n",
      "10                      with_points     3.189439\n",
      "11                             bike     3.052827\n",
      "12                           starts     3.018337\n",
      "13                     circuit_name     2.881813\n",
      "14                            rider     2.843936\n",
      "15                        shortname     2.843130\n",
      "16                         finishes     2.824810\n",
      "17                             team     2.396234\n",
      "18                         max_year     2.296543\n",
      "19                          podiums     2.277734\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data\n",
    "train_df, test_df, val_df = load_data()\n",
    "\n",
    "# 2. Feature engineering\n",
    "train_processed = feature_engineering(train_df, is_train=True)\n",
    "test_processed = feature_engineering(test_df, is_train=False)\n",
    "val_processed = feature_engineering(val_df, is_train=True)  # This was missing\n",
    "\n",
    "# 3. Prepare features\n",
    "train_final, test_final, val_final = prepare_features(train_processed, test_processed, val_processed)\n",
    "\n",
    "# 4. Get feature columns\n",
    "feature_cols = categorical_features + numerical_features\n",
    "X_test = test_final[feature_cols]\n",
    "\n",
    "# 5. Train model (or load your trained model)\n",
    "model, _ = train_model(train_final[feature_cols], train_final['Lap_Time_Seconds'], optimize_hyperparams=False)\n",
    "\n",
    "# 6. Make predictions\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "# 7. Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Unique ID': test_df['Unique ID'],\n",
    "    'Lap_Time_Seconds': test_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3839bd-f087-4084-9a66-934723a53ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adi",
   "language": "python",
   "name": "adi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
